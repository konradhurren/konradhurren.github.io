

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.42.2 with theme Tranquilpeak 0.4.3-BETA">
    <title>Gradient Descent The Smart Way</title>
    <meta name="author" content="Konrad Hurren">
    <meta name="keywords" content="">

    <link rel="icon" href="https://konradhurren.github.io/favicon.png">
    

    
    <meta name="description" content="Gradient Descent, the smart wayIn this blog post I want to document my version of a gradient descent algorithm. First we’ll take a look at the data, and fit a linear model to it to understand what we’re trying to get to. Remember we can solve for the \(\hat{\beta}\) matrix either through assuming the \(\epsilon\) are IID and solve for a closed form solution using a Maximum Likelihood Estimator (this is the Econometrics way).">
    <meta property="og:description" content="Gradient Descent, the smart wayIn this blog post I want to document my version of a gradient descent algorithm. First we’ll take a look at the data, and fit a linear model to it to understand what we’re trying to get to. Remember we can solve for the \(\hat{\beta}\) matrix either through assuming the \(\epsilon\) are IID and solve for a closed form solution using a Maximum Likelihood Estimator (this is the Econometrics way).">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Gradient Descent The Smart Way">
    <meta property="og:url" content="/2018/07/gradient-descent-the-smart-way/">
    <meta property="og:site_name" content="A strong cup of coffee and a comfortable chair">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="A strong cup of coffee and a comfortable chair">
    <meta name="twitter:description" content="Gradient Descent, the smart wayIn this blog post I want to document my version of a gradient descent algorithm. First we’ll take a look at the data, and fit a linear model to it to understand what we’re trying to get to. Remember we can solve for the \(\hat{\beta}\) matrix either through assuming the \(\epsilon\) are IID and solve for a closed form solution using a Maximum Likelihood Estimator (this is the Econometrics way).">
    
    

    
    

    
      <meta property="og:image" content="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://konradhurren.github.io/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://konradhurren.github.io/">A strong cup of coffee and a comfortable chair</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://konradhurren.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://konradhurren.github.io/#about">
          <img class="sidebar-profile-picture" src="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Konrad Hurren</h4>
        
          <h5 class="sidebar-profile-bio">Perpetual apprentice; economist; strong opinions, loosely held</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Gradient Descent The Smart Way
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-07-15T00:00:00Z">
        
  July 15, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="https://konradhurren.github.io/categories/r">R</a>, 
    
      <a class="category-link" href="https://konradhurren.github.io/categories/machine-learning">machine learning</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <div id="gradient-descent-the-smart-way" class="section level1">
<h1>Gradient Descent, the smart way</h1>
<p>In this blog post I want to document my version of a gradient descent algorithm. First we’ll take a look at the data, and fit a linear model to it to understand what we’re trying to get to. Remember we can solve for the <span class="math inline">\(\hat{\beta}\)</span> matrix either through assuming the <span class="math inline">\(\epsilon\)</span> are IID and solve for a closed form solution using a Maximum Likelihood Estimator (this is the Econometrics way). OR, we can design an algorithm that gets closer and closer to the closed form solution at each iteration. This is the Machine Learning way.</p>
<p>The Machine Learning and the Econometrics way are both getting to the same solution in the case of linear regression.</p>
<p>The dataset I’m using is some made up data used in the Machine Learning course on Coursera.</p>
<p>So let’s see what we’re dealing with. Below I plot the data as points, and fit a linear model using R’s lm() function. R’s lm() function estimates that <span class="math display">\[\mathbf{\hat{\beta}} = \left[\begin{array}
{r}
-3.9 \\
1.19 \\
\end{array}\right]\]</span></p>
<p>The predicted values form the lm() function are shown in <span style="color:red">red</span>.</p>
<p><img src="https://konradhurren.github.io/post/2018-07-15-gradient-descent-the-smart-way_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Now on to my Gradient Descent algorithm.</p>
<pre class="r"><code># set the hyper-parameters

learn &lt;- 0.01
numits &lt;- 2000
n &lt;- length(y)

# initialize beta

beta &lt;- matrix(0, 2, 1)

# we also want a vector that stores the cost at each iteration (so we can graph it later)
cost_history &lt;- rep(0, numits)

# we want a function to compute the cost, and a variable to store it

costfun &lt;- function(x, y, beta){
  h &lt;- x%*%beta
  error &lt;- h - y
  cost_at_beta &lt;-  sum((error)^2)/(2*n)
  return(cost_at_beta)
}</code></pre>
<p>Now we want the actual gradient descent. This algorithm needs to take x, y, beta, the learning rate, and the number of iterations. Then, at ach iteration update the beta using the “update amount” it found from the derivative of the cost function evaluated at the previous beta. Inside this function there will be a routine that stores the cost at each iteration in the vector we created during the initialization step. This routine uses the function I made called costfun.</p>
<p>Finally, we want to be able to look at the estimated beta AND the estimated costs so we need to make a list of those two vectors</p>
<pre class="r"><code>gradient_desc &lt;- function(x, y, beta, learn, numits){
 
  for(i in 1:numits) { 
  h &lt;- x%*%beta
  error &lt;- h - y
  beta_change &lt;- learn*(t(x)%*%(error))/(n)
    beta &lt;- beta - beta_change
    cost_history[i] &lt;- costfun(x, y, beta)
  }
  results &lt;- list(beta, cost_history)
  return(results)
}

# and store everything (I did this in a weird way, you can also put these inside the functions, but this way is intuitive to me)

results &lt;- gradient_desc(x, y, beta, learn, numits)
beta &lt;- results[[1]]
cost_history &lt;- results[[2]]</code></pre>
<p>Now let’s graph the cost as a function of the number of iterations. We do this to test if our cost function is well behaved and as an idiot check. What we want is a declining function.</p>
<p><img src="https://konradhurren.github.io/post/2018-07-15-gradient-descent-the-smart-way_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Cool, the function sharply declines and then levels off. This shape implies the cost function is well behaved and the Gradient Descent algorithm has been implemented properly.</p>
<p>Let’s now graph the data, the fitted values from lm(), and the fitted values from my Gradient Descent algorithm.</p>
<p><img src="https://konradhurren.github.io/post/2018-07-15-gradient-descent-the-smart-way_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Excellent. The values are VERY close (-3.79 and 1.18, compared to lm()’s -3.9 and 1.19). This is expected as explained before: in the linear regression context Gradient Descent will approximate the linear regression. Once we start considering other model types (like decision trees, neural networks, etc.) the lm() function will fall over.</p>
<p>And with that, we’re done.</p>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/08/logistic-regression-gradient-descent/" data-tooltip="Logistic regression - Gradient Descent">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/07/gradient-descent-part-deux-or-part-duh/" data-tooltip="Gradient Descent part deux (or part duh)">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 Konrad Hurren. All Rights Reserved


    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
      </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/08/logistic-regression-gradient-descent/" data-tooltip="Logistic regression - Gradient Descent">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/07/gradient-descent-part-deux-or-part-duh/" data-tooltip="Gradient Descent part deux (or part duh)">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fkonradhurren.github.io%2F2018%2F07%2Fgradient-descent-the-smart-way%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fkonradhurren.github.io%2F2018%2F07%2Fgradient-descent-the-smart-way%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=https%3A%2F%2Fkonradhurren.github.io%2F2018%2F07%2Fgradient-descent-the-smart-way%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Konrad Hurren</h4>
    
      <div id="about-card-bio">Perpetual apprentice; economist; strong opinions, loosely held</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Professional economist; hobby data scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        New Zealand
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/08/logistic-regression-gradient-descent/">
                <h3 class="media-heading">Logistic regression - Gradient Descent</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Logistic Regression with gradient descentIn this post we’re looking at my second favourite machine learning algorithm - logistic regression. This algorithm is incredibly useful: Imagine you’re a central planner and you have a dataset of, let’s say, 18 - 24 year olds. Prior to gathering this data you decided you would randomly allocate driver’s licences to half of these 18 - 24 year olds without reuiring them to sit their formal tests.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
                <h3 class="media-heading">Gradient Descent The Smart Way</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Gradient Descent, the smart wayIn this blog post I want to document my version of a gradient descent algorithm. First we’ll take a look at the data, and fit a linear model to it to understand what we’re trying to get to. Remember we can solve for the \(\hat{\beta}\) matrix either through assuming the \(\epsilon\) are IID and solve for a closed form solution using a Maximum Likelihood Estimator (this is the Econometrics way).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/gradient-descent-part-deux-or-part-duh/">
                <h3 class="media-heading">Gradient Descent part deux (or part duh)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">So in my last post I described the maths and intuition of gradient descent. Now I want to go through how to implement gradient descent for a linear regression in R.
During the building phase for this post I ran through the gradient descent algorithm the “dumb” way just to cement in my own mind how it’s working. And I thought that process might actually be quite instructive for a blog post.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
                <h3 class="media-heading">Gradient Descent part 1</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Intro to Gradient DescentWhat’s going on hereThis is my first Data Science post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.
The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/welcome-to-konrad-s-blog/">
                <h3 class="media-heading">Welcome to Konrad&#39;s blog</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">WelcomeWho’s Konrad, what is this blog and why am I here?I have an educational background in economics and econometrics; as a naturally inquisitive person, after university I started reading things unrelated to my job. This lead me to finding this half new half old thing called Machine Learning . After reading through some of the basics I thought “hey some of this looks incredibly similar to econometrics, with some nomenclature differences.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         5 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://konradhurren.github.io/images/coffee_background.jpeg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://konradhurren.github.io/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = 'https:\/\/konradhurren.github.io\/2018\/07\/gradient-descent-the-smart-way\/';
          
            this.page.identifier = '\/2018\/07\/gradient-descent-the-smart-way\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'hugo-tranquilpeak-theme';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>


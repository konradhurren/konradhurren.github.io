

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.42.2 with theme Tranquilpeak 0.4.3-BETA">
    <title>Gradient Descent part 1</title>
    <meta name="author" content="Konrad Hurren">
    <meta name="keywords" content="">

    <link rel="icon" href="https://konradhurren.github.io/favicon.png">
    

    
    <meta name="description" content="Intro to Gradient DescentWhat’s going on hereThis is my first Data Science post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.
The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course.">
    <meta property="og:description" content="Intro to Gradient DescentWhat’s going on hereThis is my first Data Science post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.
The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Gradient Descent part 1">
    <meta property="og:url" content="/2018/07/gradient-descent-part-1/">
    <meta property="og:site_name" content="A strong cup of coffee and a comfortable chair">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="A strong cup of coffee and a comfortable chair">
    <meta name="twitter:description" content="Intro to Gradient DescentWhat’s going on hereThis is my first Data Science post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.
The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course.">
    
    

    
    

    
      <meta property="og:image" content="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://konradhurren.github.io/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://konradhurren.github.io/">A strong cup of coffee and a comfortable chair</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://konradhurren.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://konradhurren.github.io/#about">
          <img class="sidebar-profile-picture" src="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Konrad Hurren</h4>
        
          <h5 class="sidebar-profile-bio">Perpetual apprentice; economist; strong opinions, loosely held</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://konradhurren.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Gradient Descent part 1
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-07-03T00:00:00Z">
        
  July 3, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="https://konradhurren.github.io/categories/r">R</a>, 
    
      <a class="category-link" href="https://konradhurren.github.io/categories/machine-learning">machine learning</a>, 
    
      <a class="category-link" href="https://konradhurren.github.io/categories/intuition">intuition</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <div id="intro-to-gradient-descent" class="section level1">
<h1>Intro to Gradient Descent</h1>
<div id="whats-going-on-here" class="section level2">
<h2>What’s going on here</h2>
<p>This is my first <em>Data Science</em> post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.</p>
<p>The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course. It’s my understanding that Gradient Descent is the basis of how machines <em>learn</em>.</p>
</div>
<div id="linear-regression" class="section level2">
<h2>linear regression</h2>
<p>My understanding of linear regression is how it was presented my the lecturers I had at univisersity. Namely, we look at our data and say that the following model might fit.</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{1i} + \beta_{2i}x_{2i} + ... + \beta_{k}x_{ki} + \epsilon_{i}\]</span> I know everyone likes to present it in matrix form or sum notation but I always conceive it in the above form. Anyway basically we’re saying “our ys are a linear combination of some xs and there’s a random noise thing there too”.</p>
<p>Econometricians look at this and go “if we assume all the <span class="math inline">\(\epsilon_{i}\)</span> are normally distributed with the same mean and variance then we can estimate it using Ordinary Least Squares”. I’ll leave it up to the reader to dive into this if you wish <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares" class="uri">https://en.wikipedia.org/wiki/Ordinary_least_squares</a>.</p>
<p>But the data scientist? Interestingly they approach this problem and say “we want to estimate this cool equation (the above one minus the <span class="math inline">\(\epsilon_{i}\)</span>) but we don’t like assumptions. We want to build a MACHINE that does it for us.”</p>
<p>Then they go about designing this <em>machine</em>. They conceive of some hypothesized line that will fit all the points, design a function that tells the machine off when it makes a guess too far away from this line (a <em>cost function</em>). Then they roll a ball down a hill.</p>
<p>Wait, what.</p>
<p>That’s how Gradient Descent is apparently conceived, as rolling a ball down a hill: You roll it from where you stand, it rolls down to the bottom, then it rolls up a bit because physics and stuff, then it rolls down again, and up a little bit, and down again, and up maybe a tiny bit more, then finally it comes to rest.</p>
<p>What a brilliant concept. As in the physical world, if you want to find the bottom of a hill, you roll a ball down it. In the mathematical world, if you want to find a bottom (minima) of a function you roll a ball down it!</p>
<p>For a linear model the hypothesized line is</p>
<p><span class="math display">\[\hat{y}_{i} = \hat{\beta}_{0} + \hat{\beta}_{1}x_{1i} + \hat{\beta}_{2}x_{2i} + ... + \hat{\beta}_{k}x_{ki}\]</span></p>
<p>And so the data scientist sets up a cost functin like <span class="math display">\[cost = \frac{1}{2n}\sum_{i = 1}^n (\hat{y_i} - y_{i})^2\]</span></p>
<p>The 2 in <span class="math inline">\(\frac{1}{2n}\)</span> is in there for convenience because of course when we go to minimize this function we want to take the first derivative. And so the ball is rolled down the hill of this cost function to minimize it.</p>
<p>And of course to minimize a function we take the first derivative and set it to 0 (well, I lie, this just finds a stationary point on the function whether that’s a minima or maxima we don’t know until we take a second derivative).</p>
<p>And we know the first derivative can be written as: <span class="math display">\[\frac{1}{n} \sum_{i = 1}^n (\hat{y_i} - y_{i})x_{i}\]</span> For the “intercept” as it’s called in econmetrics, the <span class="math inline">\(\beta_{0}\)</span>. This simplifies to <span class="math display">\[\frac{1}{n} \sum_{i = 1}^n (\hat{y_i} - y_{i})\]</span></p>
<p>because <span class="math inline">\(x_{0}= 1\)</span></p>
<p>And so an algorithm that will roll a ball down a hill until it find the bottom will be:</p>
<p>Repeat until convergence: <span class="math display">\[\beta_{0} := \beta_{0} -\alpha \frac{1}{n} \sum_{i = 1}^n (\hat{y_i} - y_{i})\]</span> <span class="math display">\[\beta_{j} := \beta_{j} -  \alpha \frac{1}{n} \sum_{i = 1}^n (\hat{y_i} - y_{i})x_{i}\]</span> Where <span class="math inline">\(\alpha\)</span> is the <em>learning rate</em> which I think of as how fast you push the ball when you roll it down the hill. If you push it really hard it will roll to the bottom, then roll up the slope on the other side really quite high, potentially this could cause it to roll into the next valley! Which might be a local minima instead f a global minima.</p>
<p>I love that Machine Learning, especially Gradient Descent feels more experimental than econometrics. To solve this exact problem in econometrics we would have assumed the <span class="math inline">\(\epsilon\)</span>s are Gaussian and derived a closed form expression for <span class="math inline">\(\beta_{j}\)</span>.</p>
<p>Anyway that’s the maths and a bit of intuition, in my next post i’m going to write a function in R that <em>does</em> gradient descent. We’ll compare the results of a linear model fit using this to one fit using the lm function in R. Spoiler alert - they’re gonna be similar.</p>
<p>In the post after that I want to stretech my R skills a bit by re-writing the gradient descent function so that we can see what value of <span class="math inline">\(\alpha\)</span> is “best” for a particular cost function. And also test how many iterations the algorithm needs to converge when we scale our variables versus when we don’t.</p>
</div>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://konradhurren.github.io/tags/machine-learning/">Machine learning</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/07/gradient-descent-part-deux-or-part-duh/" data-tooltip="Gradient Descent part deux (or part duh)">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/07/welcome-to-konrad-s-blog/" data-tooltip="Welcome to Konrad&#39;s blog">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 Konrad Hurren. All Rights Reserved


    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
      </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/07/gradient-descent-part-deux-or-part-duh/" data-tooltip="Gradient Descent part deux (or part duh)">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://konradhurren.github.io/2018/07/welcome-to-konrad-s-blog/" data-tooltip="Welcome to Konrad&#39;s blog">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fkonradhurren.github.io%2F2018%2F07%2Fgradient-descent-part-1%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fkonradhurren.github.io%2F2018%2F07%2Fgradient-descent-part-1%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=https%3A%2F%2Fkonradhurren.github.io%2F2018%2F07%2Fgradient-descent-part-1%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://cdn1.iconfinder.com/data/icons/ninja-things-1/1772/ninja-simple-512.png" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Konrad Hurren</h4>
    
      <div id="about-card-bio">Perpetual apprentice; economist; strong opinions, loosely held</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Professional economist; hobby data scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        New Zealand
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/08/logistic-regression-gradient-descent/">
                <h3 class="media-heading">Logistic regression - Gradient Descent</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Logistic Regression with gradient descentIn this post we’re looking at my second favourite machine learning algorithm - logistic regression. This algorithm is incredibly useful: Imagine you’re a central planner and you have a dataset of, let’s say, 18 - 24 year olds. Prior to gathering this data you decided you would randomly allocate driver’s licences to half of these 18 - 24 year olds without reuiring them to sit their formal tests.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/gradient-descent-the-smart-way/">
                <h3 class="media-heading">Gradient Descent The Smart Way</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Gradient Descent, the smart wayIn this blog post I want to document my version of a gradient descent algorithm. First we’ll take a look at the data, and fit a linear model to it to understand what we’re trying to get to. Remember we can solve for the \(\hat{\beta}\) matrix either through assuming the \(\epsilon\) are IID and solve for a closed form solution using a Maximum Likelihood Estimator (this is the Econometrics way).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/gradient-descent-part-deux-or-part-duh/">
                <h3 class="media-heading">Gradient Descent part deux (or part duh)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">So in my last post I described the maths and intuition of gradient descent. Now I want to go through how to implement gradient descent for a linear regression in R.
During the building phase for this post I ran through the gradient descent algorithm the “dumb” way just to cement in my own mind how it’s working. And I thought that process might actually be quite instructive for a blog post.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/gradient-descent-part-1/">
                <h3 class="media-heading">Gradient Descent part 1</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Intro to Gradient DescentWhat’s going on hereThis is my first Data Science post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.
The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://konradhurren.github.io/2018/07/welcome-to-konrad-s-blog/">
                <h3 class="media-heading">Welcome to Konrad&#39;s blog</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">WelcomeWho’s Konrad, what is this blog and why am I here?I have an educational background in economics and econometrics; as a naturally inquisitive person, after university I started reading things unrelated to my job. This lead me to finding this half new half old thing called Machine Learning . After reading through some of the basics I thought “hey some of this looks incredibly similar to econometrics, with some nomenclature differences.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         5 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://konradhurren.github.io/images/coffee_background.jpeg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://konradhurren.github.io/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = 'https:\/\/konradhurren.github.io\/2018\/07\/gradient-descent-part-1\/';
          
            this.page.identifier = '\/2018\/07\/gradient-descent-part-1\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'hugo-tranquilpeak-theme';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>


<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Intuition on A strong cup of coffee and a comfortable chair</title>
    <link>/categories/intuition/</link>
    <description>Recent content in Intuition on A strong cup of coffee and a comfortable chair</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/intuition/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Gradient Descent part 1</title>
      <link>/2018/07/gradient-descent-part-1/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/gradient-descent-part-1/</guid>
      <description>Intro to Gradient DescentWhat’s going on hereThis is my first Data Science post on my blog. In this post i’ll be exploring my understanding of the Gradient Descent algorithm. My next post will explore how to implement this algorithm in R. Then i’ll have a play around with the function so we can all see the results of some pretty cool maths.
The Gradient Descent algorithm is the first algorithm presented by Andrew NG in his Machine Learning course.</description>
    </item>
    
  </channel>
</rss>